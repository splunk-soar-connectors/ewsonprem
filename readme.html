<!-- File: readme.html
  Copyright (c) 2016-2022 Splunk Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under
the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
either express or implied. See the License for the specific language governing permissions
and limitations under the License.
-->
<p>Use the Microsoft Exchange On-Premise EWS app to access a user's mailbox via EWS XML SOAP calls on an on-premise Exchange server. This can be done through impersonation, or high-level permissions. To use Splunk Phantom to organize and gain insights from email data, you need to install and connect Splunk Phantom to the Microsoft Exchange On-Premise EWS app.</p>
<h2>Impersonation and privileges</h2>
<p>When using impersonation, the app uses the current user to impersonate the target user to perform commands in the mailboxes the target user has access to. This can be configured in the user interface. When using high level permissions, many organizations configure an Exchange administrator account that has access to certain mailboxes. To give access to a user's mailbox to another user, use the <strong>Add-MailboxPermission</strong> PowerShell cmdlet on the Exchange Server.</p>
<h2>Configuration</h2>
    <ul>
        <li>EWS URL: The URL configured by the person that set up the Exchange server.</li>
        <li>EWS Version: Ensure the version in the dropdown corresponds to the version of Exchange you have installed.&nbsp;</li>
        <li>Username and Password: Use the username and password that have the correct privileges to access other mailboxes.&nbsp;</li>
        <li>(Optional) User Email Mailbox: The mailbox you will ingest data from if you use polling and to test connectivity.&nbsp;</li>
        <li>(Optional) Script with functions to preprocess containers and artifacts: The user can add a script file in the configuration parameter. The script must contain a function with the name <b>preprocess_container</b> (to pre-process the containers and the artifacts) else it will throw an error. The script should not contain <b>run_automation</b>(or any other logic to trigger active playbooks) since the app automatically handles the triggering. The implementation will first process the container according to the script and save it. The artifacts are then added to the container, processed, and saved in that order. Hence, when adding a script to process artifacts, verify if artifacts are present in the container before modifying them.&nbsp;</li>
        <li>On poll information: Configure your desired on poll settings. For example, how to ingest, the number of emails to poll, what type of information you want to extract, and once extracted, your desired level of container severity. For more information on using on poll data ingestion, see Use on poll data ingestion.&nbsp;</li>
    </ul>
<h2 id="poll_now">POLL NOW</h2>
    <p>
    POLL NOW should be used to get a sense of the containers and artifacts that are created by the app. The POLL NOW window allows the user to set the "Maximum containers" that should be ingested at this instance. Since a single container is created for each email, this value equates to the maximum emails that are ingested by the app. The app will either get the oldest email first or the latest, depending upon the configuration parameter <i>How to ingest</i>. The date used to determine the oldest or latest is what EWS calls <b>item:LastModifiedTime</b> and <b>item:DateTimeCreated</b>, which is dependent on the parameter <i>Sort mails by</i>. If an email that arrived a week ago, is moved from one folder to the folder being ingested, its LastModifiedTime will be set to the time that it was moved. But, its DateTimeCreated will be the same.
    <br/> <br/> <b>Note</b>: "Mailbox folder to be polled" parameter is case-sensitive.
    </p>
<h2 id="scheduled_polling">Scheduled Polling</h2>
    <p>This mode is used to schedule a polling action on the asset at regular intervals, which is configured via the INGEST SETTINGS tab of the asset. It makes use of the following asset configuration parameters (among others):</p>
    <ul>
        <li>Maximum emails to poll the first time</li>
            The app detects the first time it is polling an asset and will ingest this number of emails (at the most).
        <li>Maximum emails to poll</li>
            For all scheduled polls after the first, the app will ingest this number of emails.
        <li>How to ingest</li>
            Should the app be ingesting the latest emails or the oldest.
    </ul>
    <p>In the case of Scheduled Polling, on every poll, the app remembers the last email that it has ingested and will pick up from the next one in the next scheduled poll.</p>
    <h3>How to ingest</h3>
    <p>The app allows the user to configure how it should ingest emails on every scheduled poll either in the <i>oldest first</i> or the <i>latest first</i> order. Depending upon the scheduled interval and how busy the folder is, one of the following could potentially happen</p>
    <ul>
        <li>oldest first</li>
            If the app is configured to poll too slowly and the folder is so busy that on every poll the maximum ingested emails is less than the number of new emails, the app will never catch up.
        <li>latest first</li>
            If the app is configured to poll too slowly and the folder is so busy that on every poll the maximum ingested emails is less than the number of new emails, the app will drop the older emails since it is ingesting the latest emails that came into the mailbox.
    </ul>
    <p>For best results, keep the poll interval and <i>Maximum emails to poll</i> values close to the number of emails you would get within a time interval. This way, every poll will end up ingesting all the new emails.</p>
    <h3>Sort mails by</h3>
    <p>This parameter defines on which email attribute, the order <i>latest first</i>/<i>oldest first</i> should be applied. The user can configure it to any of the below values.</p>
    <ul>
        <li>updated time</li>
            The application will fetch and ingest emails with the latest updated time field of the email attribute.
        <li>created time</li>
            The application will fetch and ingest emails with the created time field of the email attribute. Be careful while using this option, as the application fetches the emails by the created time, any update made on the email after ingestion, will not be reflected in the phantom container.
    </ul>
    <br>
    <p>In case the asset is configured to poll <b>oldest first</b>, it becomes important that the <i>Maximum number of emails to poll</i> configured should be greater than the maximum number of emails generated <b>per second</b>. If the app detects it got the maximum configured emails and all occurred in the same second, it will start polling from the next second in the next polling cycle.</p>
    <h3>Run automation on duplicate event</h3>
    <p>Set this parameter to run the automation, when there is a modification in the email which is already ingested. If you don't want to trigger the automation for such small changes (in case of re-ingestion), this parameter can be set to FALSE.</p>

    <h2>Important points regarding scheduled polling</h2>
    <ul>
      <li>The accuracy of "scheduled polling" can't be assured for lower polling intervals. The variance of +/-2 minutes is acceptable in the current implementation.</li>
      <li>The interval period must be set considering various aspects. Anything below 5 minutes can be considered as less accurate.</li>
      <li>One can separate out the mail boxes to increase the accuracy of polling. For example, inbox, drafts and other folders. This allows multiple ingestions on different assets by keeping longer interval period (i.e. 5 minutes), rather than a single asset with 1 minute interval period.</li>
      <li>When the ingestion time takes longer than the interval period( i.e. When the interval period is 1-minute, and it takes 2 minutes to ingest an email), In this case, the following scenarios are possible.</li>
      <ul>
        <li>The timing can not be exact, as one ingestion must complete before the timer is resumed.</li>
        <li>It is also possible that even after turning off the scheduled polling, some emails would be ingested as the emails are queued when the ingestion takes longer than the period.</li>
        <li>Hence, it is important to set the appropriate ingestion period as per your data.</li>
      </ul>
      </ul>

    </ul>
    <h2>Artifacts created</h2>
    <p>
       The app will create the following type of artifacts:
      <ul>
      <li>Email Artifact</li>
      The email addresses that are found in the ingested email will be added as a separate artifact. Any attached email will also be scanned and the address present in the attached email will be added as a separate artifact. The emails are added as custom strings in the CEF structure in the following manner.
    <br>
      <table style="width:100%">
        <tr>
          <td><b>Artifact Field</b></td>
          <td><b>Value Details</b></td>
        </tr>
        <tr>
          <td>fromEmail</td>
          <td>The email address of the sender</td>
        </tr>
        <tr>
          <td>toEmail</td>
          <td>The email address of the receiver of the email</td>
        </tr>
        <tr>
          <td>emailHeaders</td>
          <td>A dictionary containing each email header as a key and its value as the key-value</td>
        </tr>
      </table>
    <br>

    <a href="/app_resource/microsoftexchangeonpremiseews_badc5252-4a82-4a6d-bc53-d1e503857124/img/email_artifact.png">
        <img src="/app_resource/microsoftexchangeonpremiseews_badc5252-4a82-4a6d-bc53-d1e503857124/img/email_artifact.png"/>
    </a>
    <li>IP Artifact - cef.sourceAddress</li>
        <ul>
            <li>If <b>extract_ips</b> is enabled, any IPv4 or IPv6 found in the email body will be added, with one CEF per IP.</li>
            <li>Any IP addresses found in the email are added to the CEF structure of an artifact.</li>
            <li>The CEF for an IP is cef.sourceAddress.</li>
        </ul>
    </li>
    <li>Hash Artifact - cef.fileHash</li>
        <ul>
            <li>If <b>extract_hashes</b> is enabled, any hash found in the email body will be added, with one CEF per hash.</li>
            <li>Any Hashes found in the email are added to the CEF structure of an artifact.</li>
            <li>The CEF for a hash is cef.fileHash.</li>
        </ul>
    </li>
    <li>URL Artifact - cef.requestURL</li>
        <ul>
            <li>If <b>extract_urls</b> is enabled, any URL found in the email body will be added, with one CEF per url.</li>
            <li>Any URLs or hyperlinks found are added to the CEF structure of an artifact.</li>
            <li>The CEF for a URL is cef.requestURL.</li>
        </ul>
    </li>
    <li>Domain Artifact - cef.destinationDnsDomain</li>
        <ul>
            <li>If <b>extract_domains</b> is enabled, any domain found in the email body will be added, with one CEF per domain.</li>
            <li>Domains that are part of a URL, a hyperlink or an email address are added to the CEF structure of an artifact.</li>
            <li>The CEF for a Domain is cef.destinationDnsDomain.</li>
        </ul>
    </li>
      <li>Vault Artifact
        <ul>
          <li>If the email contains any attachments, these are extracted (if <b>extract_attachments</b> is enabled) and added to the vault of the Container.</li>
          <li>At the same time, the vault ID and file name of this item is represented by a Vault Artifact.</li>
          <li>The same file can be added to the vault multiple times. In this scenario, the file name of the item added the second time onwards will be slightly different, but the vault ID will still be the same. However, there will be multiple artifacts created.</li>
          <li>Do note that the system does <i>not</i> duplicate the file bytes, only the metadata in the database.
          <table style="width:100%">
            <tr>
              <td><b>Artifact Field</b></td>
              <td><b>Value Details</b></td>
            </tr>
            <tr>
              <td>Source ID</td>
              <td>Email ID set on the server</td>
            </tr>
            <tr>
              <td>cef.vaultId</tdLavel>
              <td>Vault ID of the attachment</td>
            </tr>
            <tr>
              <td>cef.fileHashMd5</td>
              <td>MD5 hash of the attachment</td>
            </tr>
            <tr>
              <td>cef.fileHashSha1</td>
              <td>SHA1 hash of the attachment</td>
            </tr>
            <tr>
              <td>cef.fileHashSha256</td>
              <td>SHA256 hash of the attachment</td>
            </tr>
            <tr>
              <td>cef.fileName</td>
              <td>File name of the attachment</td>
            </tr>
            <tr>
              <td>cef.headers</td>
              <td>A dictionary containing each file header as a key and its value as the key-value</td>
            </tr>
          </table></li>
            <li>You will notice additional CEF fields <b>cs6</b> (value is the Vault ID) and <b>cs6Label</b>. These are added for backward compatibility only and will be deprecated in future releases. Please don't use these keys in playbooks.</li>
        </ul>
      </li>
    <a href="/app_resource/microsoftexchangeonpremiseews_badc5252-4a82-4a6d-bc53-d1e503857124/img/vault_artifact.png">
        <img src="/app_resource/microsoftexchangeonpremiseews_badc5252-4a82-4a6d-bc53-d1e503857124/img/vault_artifact.png"/>
      </ul>
    </a>
    </p>


    <h2>Copy Email</h2>
<p>To use the copy email command, follow these steps:</p>
<ol>
<li>Navigate to the Investigation page.&nbsp;</li>
<li>Click <strong>Action</strong>.</li>
<li>In the search bar, search for the copy email command.</li>
<li>Click <strong>copy email</strong>.&nbsp;</li>
<li>Click <strong>exchange, </strong>or whatever asset name you created, as the asset you want to run the <strong>copy email</strong> command on.&nbsp;</li>
<li>Enter the ID. Each email in Exchange has a unique ID. You can get this email ID from an email artifact that was previously ingested, or by running a run query action.&nbsp;</li>
<li>Enter the email address of the user you want to copy the email from and the folder you want to copy the email to.</li>
<li>&nbsp;From the message ID, click the drop down arrow and click<strong> Run Action</strong>.</li>
<li>Enter the email and the folder you want to move it to.&nbsp;</li>
<li>&nbsp;Click <strong>Launch</strong>.&nbsp;</li>
</ol>

<h3>Preprocessing Containers</h3>
<p>
It is possible to upload your own script which has functions to handle preprocessing of containers.
The artifacts which are going to be added with the container can be accessed through this container as well.
This function should accept a container and return the updated container. Also note that the name of this function
must be <b>preprocess_container</b>.
<pre class="shell">
<code>
import urlparse


def get_host_from_url(url):
    return urlparse.urlparse(url).hostname


def preprocess_container(container):

    # Match urls like https://secure.contoso.com/link/https://www.google.com
    # We want to strip 'https://secure.contoso.com/link/', and instead create
    #  a URL artifact for 'https://www.google.com'
    url_prepend = 'https://secure.contoso.com/link/'
    domain_prepend = 'secure.contoso.com'

    new_artifacts = []

    for artifact in container.get('artifacts', []):
        cef = artifact.get('cef')
        url = cef.get('requestURL')
        if url and url.lower().startswith(url_prepend):
            url = url.replace(url_prepend, '')
            artifact['cef']['requestURL'] = url
            # Create a new domain artifact for this URL
            new_artifacts.append({
                'name': 'Domain Artifact',
                'cef': {
                    'destinationDnsDomain': get_host_from_url(url)
                }
            })

        domain = cef.get('destinationDnsDomain')
        if domain and domain.lower() == domain_prepend:
            # These are the wrong domains, ignore them
            continue

        new_artifacts.append(artifact)

    if new_artifacts:
        new_artifacts[-1]['run_automation'] = True

    container['artifacts'] = new_artifacts
    return container
</code>
</pre>
In this example, many of the URLs have 'https://secure.contoso.com/link' appended to the start of them.
These URL artifacts will be tough to use in a playbook without additional processing. On top of that, all
of the associated domain artifacts will be incorrect as well, since they will all point to 'secure.contoso.com'.
</p>
<h2>Port Information</h2>
  <p>
    The app uses the HTTP/HTTPS protocol for communicating with the Microsoft Exchange On-Premise EWS Server. Below are the default ports used by Splunk SOAR.
    <table>
      <tr class=plain>
        <th>Service Name</th>
        <th>Transport Protocol</th>
        <th>Port</th>
      </tr>
      <tr>
        <td>http</td>
        <td>tcp</td>
        <td>80</td>
      </tr>
      <tr>
        <td>https</td>
        <td>tcp</td>
        <td>443</td>
      </tr>
    </table>
  </p>
